{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tarea Nº 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fecha y hora de entrega: Domingo 12 de enero, 11:59pm\n",
    "- Agregue los nombres de las personas con las que discutió esta tarea: __Jhoany Rodriguez, Andre Paredes y Fabian Galarza__\n",
    "- Envíe su tarea haciendo el `push` de su código a su repo en GitHub Classroom: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Mercado de autos usados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importa el conjunto de datos `neoauto_20240924.csv`\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ¿Cuál es el precio promedio de los autos de cada marca (`item_brand`) publicados en cada subcategoría (`item_category_2`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       item_brand item_category_2          value\n",
      "0      ALFA-ROMEO       Hatchback    8500.000000\n",
      "1      ALFA-ROMEO           Sedan    2500.000000\n",
      "2    ASTON MARTIN  Camionetas Suv       0.000000\n",
      "3    ASTON MARTIN       Deportivo       0.000000\n",
      "4    ASTON MARTIN           Sedan  149900.000000\n",
      "..            ...             ...            ...\n",
      "197         VOLVO  Camionetas Suv   41021.219512\n",
      "198         VOLVO       Deportivo    8800.000000\n",
      "199         VOLVO       Hatchback   12272.500000\n",
      "200         VOLVO           Sedan   10802.777778\n",
      "201         VOLVO   Station Wagon    6100.000000\n",
      "\n",
      "[202 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_neoauto = pd.read_csv('neoauto_20240924.csv')\n",
    "mean_value = df_neoauto.groupby(['item_brand', 'item_category_2'], as_index=False)['value'].mean()\n",
    "print(mean_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ¿Cuántos autos tienen más de 100,000 kilómetros (`item_km`) pero un precio (`item_price`) menor al promedio general?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497\n"
     ]
    }
   ],
   "source": [
    "precio_promedio_general = df_neoauto['item_price'].mean()\n",
    "autos_filtro = df_neoauto[(df_neoauto['item_km'] > 100000) & (df_neoauto['item_price'] < precio_promedio_general)]\n",
    "cantidad_autos = autos_filtro.shape[0]\n",
    "print(cantidad_autos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Encuentra el modelo (`item_name`) más caro y el más barato de cada marca (`item_brand`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       modelo_mas_caro  precio_mas_caro  \\\n",
      "item_brand                                                \n",
      "ALFA-ROMEO         alfa-romeo 147 2006           8500.0   \n",
      "ASTON MARTIN     aston martin dbx 2021         229000.0   \n",
      "AUDI                    audi rs 6 2024         220000.0   \n",
      "AUSTIN         austin mini cooper 1970              1.0   \n",
      "BAIC                     baic x55 2021          12800.0   \n",
      "...                                ...              ...   \n",
      "SWM                   swm g05 pro 2022          14000.0   \n",
      "TOYOTA               toyota hilux 2019         100000.0   \n",
      "TRIUMPH              triumph tr-7 1971          18900.0   \n",
      "VOLKSWAGEN    volkswagen teramont 2023          48900.0   \n",
      "VOLVO                 volvo xc-90 2023          84990.0   \n",
      "\n",
      "                           modelo_mas_barato  precio_mas_barato  \n",
      "item_brand                                                       \n",
      "ALFA-ROMEO           alfa-romeo alfasud 1982             2500.0  \n",
      "ASTON MARTIN          aston martin db11 2017           149900.0  \n",
      "AUDI                      audi a3 sedan 2015                0.0  \n",
      "AUSTIN               austin mini cooper 1970                1.0  \n",
      "BAIC                          baic plus 2018             7500.0  \n",
      "...                                      ...                ...  \n",
      "SWM                         swm g05 pro 2022            14000.0  \n",
      "TOYOTA        toyota land cruiser prado 2011                0.0  \n",
      "TRIUMPH                    triumph tr-7 1971            18900.0  \n",
      "VOLKSWAGEN              volkswagen bora 2015                0.0  \n",
      "VOLVO                   volvo 850 turbo 1995             2100.0  \n",
      "\n",
      "[73 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "modelo_mas_caro_barato = df_neoauto.groupby('item_brand').agg(\n",
    "    modelo_mas_caro=('item_name', lambda x: x[df_neoauto.loc[x.index, 'item_price'].idxmax()]),\n",
    "    precio_mas_caro=('item_price', 'max'),\n",
    "    modelo_mas_barato=('item_name', lambda x: x[df_neoauto.loc[x.index, 'item_price'].idxmin()]),\n",
    "    precio_mas_barato=('item_price', 'min'))\n",
    "print(modelo_mas_caro_barato)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Encuentra las tres marcas con mayor número de autos financiados por Santander (`item_financed_by`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las tres marcas con mayor número de autos financiados por Santander son:\n",
      "item_brand\n",
      "BMW       296\n",
      "TOYOTA    261\n",
      "NISSAN    228\n",
      "Name: item_brand, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "marcas_top_financiadas = df_neoauto[df_neoauto['item_financed_by'] == 'Santander'].groupby('item_brand')['item_brand'].count().nlargest(3)\n",
    "print(\"Las tres marcas con mayor número de autos financiados por Santander son:\")\n",
    "print(marcas_top_financiadas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Agrupa las publicaciones por tipo de transmisión (`item_transmission`) y calcula la desviación estándar del precio (`item_price`) para cada tipo.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desviación estándar del precio por tipo de transmisión:\n",
      "item_transmission\n",
      "Automática                 15332.729048\n",
      "Automática - Secuencial    22678.641589\n",
      "Mecánica                    8137.122127\n",
      "Name: item_price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "desvest_precio_transmision = df_neoauto.groupby('item_transmission')['item_price'].std()\n",
    "print(\"Desviación estándar del precio por tipo de transmisión:\")\n",
    "print(desvest_precio_transmision)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. ¿Cuál es el kilometraje promedio de las publicaciones con el tag \"Premium\" y de las publicaciones con el tag \"Como nuevo\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kilometraje promedio por tag:\n",
      "item_tag\n",
      "Como nuevo    35963.476190\n",
      "Premium       48400.235897\n",
      "Name: item_km, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "kilometraje_tags = df_neoauto[df_neoauto['item_tag'].isin(['Premium', 'Como nuevo'])].groupby('item_tag')['item_km'].mean()\n",
    "print(\"Kilometraje promedio por tag:\")\n",
    "print(kilometraje_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. ¿Cuáles son las marcas de vehículos para los que todos sus modelos fabricados en los últimos 5 años tienen al menos 5 publicaciones cada una?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marcas con todos sus modelos recientes (últimos 5 años) con al menos 5 publicaciones válidas:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "publicaciones_validas = df_neoauto[df_neoauto['item_price'].notna()]\n",
    "\n",
    "año_actual = 2024 # Asumimos que el año actual es 2024\n",
    "año_limite = año_actual - 5\n",
    "\n",
    "autos_recientes = publicaciones_validas[publicaciones_validas['item_year'] >= año_limite]\n",
    "\n",
    "publicaciones_por_modelo = autos_recientes.groupby(['item_brand', 'item_name']).size().reset_index(name='count') # publicaciones únicas por marca y modelo\n",
    "\n",
    "modelos_con_mas_de_5_publicaciones = publicaciones_por_modelo[publicaciones_por_modelo['count'] >= 5]\n",
    "\n",
    "modelos_por_marca = modelos_con_mas_de_5_publicaciones.groupby('item_brand')['item_name'].nunique().reset_index(name='num_modelos') # se agrupa por marca y se cuenta cuántos modelos cumplen el criterio\n",
    "\n",
    "modelos_totales_recientes = autos_recientes.groupby('item_brand')['item_name'].nunique().reset_index(name='total_modelos') # se cuentan todos los modelos recientes (últimos 5 años) por marca\n",
    "\n",
    "marcas_validas = pd.merge(modelos_por_marca, modelos_totales_recientes, on='item_brand')\n",
    "\n",
    "marcas_finales = marcas_validas[marcas_validas['num_modelos'] == marcas_validas['total_modelos']]['item_brand'] # filtro: TODOS los modelos fabricados en los últimos 5 años tienen al menos 5 publicaciones cada una\n",
    "\n",
    "print(\"Marcas con todos sus modelos recientes (últimos 5 años) con al menos 5 publicaciones válidas:\")\n",
    "print(marcas_finales.tolist()) # no existen marcas que cumplan con el requisito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evolución económica internacional**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importa el conjunto de datos de la hoja \"Data\" del archivo `pwt1001.xlsx`. El diccionario de variables está disponible en la hoja \"Legend\" del archivo Excel.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calcule el PBI per cápita real ajustado por poder de paridad de compra (PPP). Use la variable de PBI que se calcula por gasto y la población. ¿Cuáles son los 10 países top?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. \n",
    "# Cargar los datos\n",
    "file_path = \"C:/Users/HP/Downloads/pwt1001.xlsx\"\n",
    "data = pd.read_excel(file_path, sheet_name=\"Data\")\n",
    "# Calcular el PBI per cápita real PPP\n",
    "data['rgdpe_pc'] = data['rgdpe'] / data['pop']\n",
    "# Eliminar valores faltantes\n",
    "valid_data = data.dropna(subset=['rgdpe_pc', 'year'])\n",
    "# Obtener el año más reciente\n",
    "latest_year = valid_data['year'].max()\n",
    "# Identificar los top 10 países\n",
    "top_countries = (valid_data[valid_data['year'] == latest_year]\n",
    "                .nlargest(10, 'rgdpe_pc')\n",
    "                [['country', 'year', 'rgdpe_pc']]\n",
    "                .reset_index(drop=True))\n",
    "\n",
    "print(f\"\\nTop 10 países por PBI per cápita PPP ajustado (Año {int(latest_year)}):\")\n",
    "print(\"\\nRanking  País                  PBI per cápita PPP\")\n",
    "print(\"-\" * 50)\n",
    "for idx, row in top_countries.iterrows():\n",
    "    print(f\"{idx+1:<8} {row['country']:<20} {row['rgdpe_pc']:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Genera el ránking de los países con el mayor incremento del PBI per cápita real PPP entre los años 1990 y 2019. ¿Dónde se ubica Perú? Para los países que no tengan información para dichos años, puede utilizar datos provenientes de hasta dos años antes o después"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.\n",
    "data_1990_2019 = valid_data[(valid_data['year'] >= 1988) & (valid_data['year'] <= 2021)]\n",
    "df_changes = data_1990_2019.pivot(index='country', columns='year', values='rgdpe_pc')\n",
    "df_changes['change'] = df_changes[2019] - df_changes[1990]\n",
    "ranking_changes = df_changes.sort_values('change', ascending=False).reset_index()\n",
    "ranking_peru = ranking_changes[ranking_changes['country'] == 'Peru'].index[0] + 1\n",
    "\n",
    "print(\"Ranking de países con mayor incremento (1990-2019):\")\n",
    "print(ranking_changes[['country', 'change']].head(10))\n",
    "print(f\"\\nUbicación de Perú: {ranking_peru}° lugar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Para el periodo 2010-2019, calcule el promedio del índice del capital humano. ¿Qué relación existe entre esta variable y el PBI per cápita real PPP calculado previamente? ¿y el número de horas laboradas al año por los trabajadores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.\n",
    "data_2010_2019 = valid_data[(valid_data['year'] >= 2010) & (valid_data['year'] <= 2019)]\n",
    "human_capital_avg = data_2010_2019.groupby('country')['hc'].mean().reset_index()\n",
    "relation_df = data_2010_2019.groupby('country').agg({\n",
    "    'rgdpe_pc': 'mean',\n",
    "    'hc': 'mean',\n",
    "    'avh': 'mean'\n",
    "}).reset_index()\n",
    "correlacion_hc_gdp = relation_df['hc'].corr(relation_df['rgdpe_pc'])\n",
    "correlacion_hc_avh = relation_df['hc'].corr(relation_df['avh'])\n",
    "print(\"Promedio del índice de capital humano por país (2010-2019):\")\n",
    "print(human_capital_avg.sort_values('hc', ascending=False).head(10))\n",
    "print(\"\\nCorrelaciones:\")\n",
    "print(f\"Capital Humano - PBI per cápita: {correlacion_hc_gdp:.3f}\")\n",
    "print(f\"Capital Humano - Horas trabajadas: {correlacion_hc_avh:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. A partir de la variable del precio de los hogares, calcula los países y los años en los cuales se registró la mayor inflación anual para todo el periodo de tiempo disponible en la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.\n",
    "data_sorted = data.sort_values(['country', 'year'])\n",
    "data_sorted['inflation'] = data_sorted.groupby('country')['pl_con'].pct_change() * 100\n",
    "data_sorted = data_sorted.replace([float('inf'), float('-inf')], float('nan'))\n",
    "max_inflation = data_sorted.dropna(subset=['inflation'])\n",
    "top_inflation = (max_inflation\n",
    "                .sort_values('inflation', ascending=False)\n",
    "                .head(10)[['country', 'year', 'inflation']]\n",
    "                .reset_index(drop=True))\n",
    "print(\"Top 10 casos de mayor inflación anual registrada:\")\n",
    "print(\"\\nPaís\\t\\tAño\\tInflación (%)\")\n",
    "print(\"-\" * 40)\n",
    "for _, row in top_inflation.iterrows():\n",
    "    print(f\"{row['country']:<15} {int(row['year'])}\\t{row['inflation']:,.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. ¿Cuáles son los países con la mayor cantidad de missing values en la variable de productividad total de factores a precios corrientes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.\n",
    "missing_tfp = (data\n",
    "               .groupby('country')['ctfp']  # Agrupamos por país y usamos la variable ctfp\n",
    "               .apply(lambda x: x.isna().sum())  # Contamos NaN\n",
    "               .sort_values(ascending=False)  # Ordenamos de mayor a menor\n",
    "               .reset_index(name='missing_count'))  # Reiniciamos el índice\n",
    "total_years = data.groupby('country').size().reset_index(name='total_years')\n",
    "missing_tfp = (missing_tfp\n",
    "               .merge(total_years, on='country')\n",
    "               .assign(missing_percentage = lambda x: (x.missing_count / x.total_years * 100)))\n",
    "print(\"Países con mayor cantidad de valores faltantes en PTF:\")\n",
    "print(\"\\nPaís\\t\\t\\tValores Faltantes\\tPorcentaje\\tTotal Años\")\n",
    "print(\"-\" * 70)\n",
    "for _, row in missing_tfp.head(15).iterrows():\n",
    "    print(f\"{row['country']:<20} {int(row['missing_count']):<20} {row['missing_percentage']:,.1f}%\\t\\t{row['total_years']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.  Agrupa los datos por país y calcula el promedio de las horas trabajadas anuales (avh) y de la educación promedio (hc) para el periodo 2000-2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.\n",
    "data_2000_2020 = valid_data[(valid_data['year'] >= 2000) & (valid_data['year'] <= 2020)]\n",
    "# Calcular promedios por país\n",
    "country_averages = (data_2000_2020\n",
    "                   .groupby('country')\n",
    "                   .agg({\n",
    "                       'avh': 'mean',  # promedio de horas trabajadas\n",
    "                       'hc': 'mean',   # promedio de capital humano (educación)\n",
    "                       'year': ['count', 'min', 'max']  # estadísticas de años disponibles\n",
    "                   })\n",
    "                   .round(2)  # redondear a 2 decimales\n",
    "                   .reset_index())\n",
    "# Renombrar columnas para claridad\n",
    "country_averages.columns = ['country', 'avg_hours', 'avg_education', 'years_count', 'start_year', 'end_year']\n",
    "# Ordenar por horas trabajadas descendente\n",
    "country_averages_sorted = country_averages.sort_values('avg_hours', ascending=False)\n",
    "\n",
    "print(\"\\nPromedios por país (2000-2020):\")\n",
    "print(\"\\nPaís                  Horas Trabajadas    Índice Educación    Periodo\")\n",
    "print(\"-\" * 75)\n",
    "for _, row in country_averages_sorted.iterrows():\n",
    "    print(f\"{row['country']:<20} {row['avg_hours']:>10,.1f}        {row['avg_education']:>8.2f}          {int(row['start_year'])}-{int(row['end_year'])}\")\n",
    "\n",
    "# Calcular algunas estadísticas descriptivas\n",
    "print(\"\\nEstadísticas descriptivas:\")\n",
    "print(\"\\nHoras trabajadas:\")\n",
    "print(country_averages['avg_hours'].describe().round(2))\n",
    "print(\"\\nÍndice de educación:\")\n",
    "print(country_averages['avg_education'].describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.  Genere una variable que ordene a los países según el porcetaje de formación brutal de capital del 2019. Luego, estable diez grupos a manera de deciles. ¿En qué decil se ubica Péru? Vuelva a calcular usando la información de 1990. ¿El Perú se mantiene en el mismo décil o cambia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. \n",
    "# Función para calcular deciles y posición de Perú\n",
    "def calcular_deciles(data, año):\n",
    "    # Filtrar datos del año específico\n",
    "    data_año = data[data['year'] == año].copy()\n",
    "    # Calcular el porcentaje de formación bruta de capital\n",
    "    data_año['fbk_percent'] = data_año['csh_i'] * 100\n",
    "    # Ordenar países y asignar deciles (1-10)\n",
    "    data_año['decil'] = pd.qcut(data_año['fbk_percent'], q=10, labels=range(1,11))\n",
    "    # Obtener posición de Perú\n",
    "    peru_data = data_año[data_año['country'] == 'Peru']\n",
    "    # Ordenar países por porcentaje para ver ranking completo\n",
    "    ranking = data_año.sort_values('fbk_percent', ascending=False)\n",
    "    return peru_data, ranking\n",
    "# Calcular para 2019\n",
    "peru_2019, ranking_2019 = calcular_deciles(valid_data, 2019)\n",
    "# Calcular para 1990\n",
    "peru_1990, ranking_1990 = calcular_deciles(valid_data, 1990)\n",
    "\n",
    "print(\"Análisis de Formación Bruta de Capital:\")\n",
    "print(\"\\nAño 2019:\")\n",
    "print(f\"Perú se ubica en el decil: {peru_2019['decil'].iloc[0]}\")\n",
    "print(f\"Porcentaje de FBK: {peru_2019['fbk_percent'].iloc[0]:.2f}%\")\n",
    "\n",
    "print(\"\\nAño 1990:\")\n",
    "print(f\"Perú se ubica en el decil: {peru_1990['decil'].iloc[0]}\")\n",
    "print(f\"Porcentaje de FBK: {peru_1990['fbk_percent'].iloc[0]:.2f}%\")\n",
    "\n",
    "# Mostrar rankings completos\n",
    "print(\"\\nRanking 2019 (Top 10):\")\n",
    "print(ranking_2019[['country', 'fbk_percent', 'decil']].head(10))\n",
    "\n",
    "print(\"\\nRanking 1990 (Top 10):\")\n",
    "print(ranking_1990[['country', 'fbk_percent', 'decil']].head(10))\n",
    "\n",
    "# Mostrar cambio en la posición relativa\n",
    "cambio = peru_2019['decil'].iloc[0] - peru_1990['decil'].iloc[0]\n",
    "print(f\"\\nCambio en la posición de Perú:\")\n",
    "if cambio == 0:\n",
    "    print(\"Perú se mantiene en el mismo decil\")\n",
    "elif cambio > 0:\n",
    "    print(f\"Perú subió {abs(cambio)} deciles\")\n",
    "else:\n",
    "    print(f\"Perú bajó {abs(cambio)} deciles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Transacciones Financieras**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importa el conjunto de datos `base_financiera.csv`\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Filtra todas las transacciones de tipo \"Debit\" en las que el monto sea mayor a 200, y calcula el monto total de esas transacciones. Además, determina cuántos clientes únicos realizaron esas transacciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monto total de transacciones: 2847871.75\n",
      "Número de clientes únicos: 200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "#Importamos la base de datos \"Base financiera\" en formato CSV desde el terminal local:\n",
    "data_base = \"C:\\GitHub - Q -LAB\\tarea-4-rodriguez-paredes-galarza\\base_financiera.csv\"\n",
    "\n",
    "# Guardamos la Base de datos en una variable con Pandas.\n",
    "data = pd.read_csv('base_financiera.csv')\n",
    "\n",
    "# Filtramos las transacciones de tipo \"Debit\" con monto amyores a 200\n",
    "filtered_data = data[(data['Transaction_Type'] == 'Debit') & (data['Amount'] > 200)]\n",
    "\n",
    "# Calculamos el número total de variaciones en los datos filtrados\n",
    "total_amount = filtered_data['Amount'].sum()\n",
    "\n",
    "# Determinamos el número de clientes únicos\n",
    "unique_customers = filtered_data['Customer_ID'].nunique()\n",
    "\n",
    "# Resultados\n",
    "print(f\"Monto total de transacciones: {total_amount}\")\n",
    "print(f\"Número de clientes únicos: {unique_customers}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Identifica las transacciones con valores nulos en la columna (`Amount`) . Rellena esos valores con la mediana de los montos por tipo de transacción (`Transaction_Type`) y luego calcula el monto total de transacciones por región (`region`) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transacciones con valores nulos en 'Amount':\n",
      "      Transaction_ID Customer_ID        Date  Amount Transaction_Type Region\n",
      "34              1035        C043  2023-02-04     NaN            Debit   East\n",
      "40              1041        C051  2023-01-01     NaN           Credit   West\n",
      "60              1061        C086  2023-01-21     NaN            Debit   East\n",
      "66              1067        C179  2023-01-27     NaN           Credit   East\n",
      "82              1083        C076  2023-01-03     NaN            Debit  South\n",
      "...              ...         ...         ...     ...              ...    ...\n",
      "1944            2945        C134  2023-01-25     NaN           Credit   West\n",
      "1967            2968        C150  2023-01-08     NaN            Debit  South\n",
      "2015            1276        C047  2023-02-05     NaN           Credit   West\n",
      "2018            2647        C068  2023-01-07     NaN            Debit  North\n",
      "2023            2084        C123  2023-01-04     NaN            Debit   East\n",
      "\n",
      "[113 rows x 6 columns]\n",
      "\n",
      "Valores nulos después de rellenar:\n",
      "0\n",
      "\n",
      "Monto total de transacciones por región:\n",
      "Region\n",
      "East     1269409.53\n",
      "North    1321224.96\n",
      "South    1208300.23\n",
      "West     1233552.50\n",
      "Name: Amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Importamos la base de datos \"Base financiera\" en formato CSV desde el terminal local:\n",
    "data_base = r\"C:\\GitHub - Q -LAB\\tarea-4-rodriguez-paredes-galarza\\base_financiera.csv\"\n",
    "# Cargamos la base de datos desde el archivo CSV\n",
    "data = pd.read_csv(data_base)\n",
    "\n",
    "# Identificamos transacciones con valores nulos en la columna \"Amount\":\n",
    "missing_values = data[data['Amount'].isnull()]\n",
    "print(\"Transacciones con valores nulos en 'Amount':\")\n",
    "print(missing_values)\n",
    "\n",
    "# Calculamos la mediana del monto por tipo de transacción:\n",
    "medians_by_type = data.groupby('Transaction_Type')['Amount'].median()\n",
    "\n",
    "# Rellenamos valores nulos con la mediana:\n",
    "data['Amount'] = data.apply(\n",
    "    lambda row: medians_by_type[row['Transaction_Type']] if pd.isnull(row['Amount']) else row['Amount'], axis=1\n",
    ")\n",
    "\n",
    "# Verificamos que no hay valores nulos:\n",
    "print(\"\\nValores nulos después de rellenar:\")\n",
    "print(data['Amount'].isnull().sum())\n",
    "\n",
    "# Calculamos el monto total de transacciones por región:\n",
    "total_by_region = data.groupby('Region')['Amount'].sum()\n",
    "\n",
    "# Mostrar resultados:\n",
    "print(\"\\nMonto total de transacciones por región:\")\n",
    "print(total_by_region)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Busca transacciones duplicadas considerando las columnas (`Customer_ID`) y (`Date`). Elimina los duplicados manteniendo solo la primera ocurrencia. Luego, agrupa las transacciones restantes por (`Customer_ID`) y calcula el monto promedio y la cantidad de transacciones por cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de transacciones duplicadas: 234\n",
      "\n",
      "Datos agrupados por cliente:\n",
      "    Customer_ID  Average_Amount  Transaction_Count\n",
      "0          C001     3334.711875                 17\n",
      "1          C002     1881.827778                  9\n",
      "2          C003     3102.125000                 14\n",
      "3          C004     3053.882000                  7\n",
      "4          C005     3364.053333                  6\n",
      "..          ...             ...                ...\n",
      "195        C196     2566.555000                 10\n",
      "196        C197     2530.674286                 14\n",
      "197        C198     2484.925000                 12\n",
      "198        C199     3062.287500                  5\n",
      "199        C200     2130.977500                  5\n",
      "\n",
      "[200 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_base = r\"C:\\GitHub - Q -LAB\\tarea-4-rodriguez-paredes-galarza\\base_financiera.csv\"\n",
    "\n",
    "data = pd.read_csv(data_base)\n",
    "\n",
    "# Buscamos transacciones duplicadas considerando las columnas \"Customer_ID\" y \"Date\"\n",
    "duplicates = data.duplicated(subset=['Customer_ID', 'Date'], keep='first')\n",
    "print(f\"Número de transacciones duplicadas: {duplicates.sum()}\")\n",
    "\n",
    "# Eliminamos duplicados, manteniendo solo la primera ocurrencia\n",
    "data_cleaned = data.drop_duplicates(subset=['Customer_ID', 'Date'], keep='first')\n",
    "\n",
    "# Agrupamos por \"Customer_ID\" y calculamos monto promedio y cantidad de transacciones por cliente\n",
    "grouped_data = data_cleaned.groupby('Customer_ID').agg(\n",
    "    Average_Amount=('Amount', 'mean'),\n",
    "    Transaction_Count=('Transaction_ID', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Mostramos resultados\n",
    "print(\"\\nDatos agrupados por cliente:\")\n",
    "print(grouped_data)\n",
    "\n",
    "# COMO ADICONAL: Guardamos la base de datos \"limpiada\" (con los cambios):\n",
    "grouped_data.to_csv(r\"C:\\GitHub - Q -LAB\\tarea-4-rodriguez-paredes-galarza\\resultados_por_cliente.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
